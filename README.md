# XiaoZhu_demo

# 第一部分： 爬取数据<br>
1. 首先找出主页列表页的url地址，将该页面的html解析出详情页的url地址和下一页的url地址。将地址保存为一个队列，防止重复爬取。<br/>
2. 在多线程主程序中添加一个参数max_depth，确定爬虫的深度。防止"爬虫陷阱"。找出列表页和详情页的url不同，利用re模块正则表达式找出需要保存在mongodb数据中的url.调用一个回调函数用BeautifulSoup模块进行解析数据。<br/>
3. 利用threading模块展开多个线程，提高爬虫效率。默认5个线程。<br/>
4. 下载页面的模块设置减速器，即相同域名的访问要间隔一定时间。<br/>
5. 因为利用了mongodb缓存数据库，还是要熟悉mongodb的基本操作。</br>

# 第二部分： 清洗数据<br>



# 第三部分： 分析数据<br>

